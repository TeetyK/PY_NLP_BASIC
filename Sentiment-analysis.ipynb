{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "716cfecf",
   "metadata": {},
   "source": [
    "# 1.Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73b0756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4a17023",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27defecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [Path('C:/Users/home/.fastai/data/imdb_sample/texts.csv')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43496bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "is_valid",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "ac74ca32-0b88-47a5-b3c4-de11b9c58ede",
       "rows": [
        [
         "0",
         "negative",
         "Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!",
         "False"
        ],
        [
         "1",
         "positive",
         "This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.<br /><br />But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is some merit in this view, but it's also true that no one forced Hindus and Muslims in the region to mistreat each other as they did around the time of partition. It seems more likely that the British simply saw the tensions between the religions and were clever enough to exploit them to their own ends.<br /><br />The result is that there is much cruelty and inhumanity in the situation and this is very unpleasant to remember and to see on the screen. But it is never painted as a black-and-white case. There is baseness and nobility on both sides, and also the hope for change in the younger generation.<br /><br />There is redemption of a sort, in the end, when Puro has to make a hard choice between a man who has ruined her life, but also truly loved her, and her family which has disowned her, then later come looking for her. But by that point, she has no option that is without great pain for her.<br /><br />This film carries the message that both Muslims and Hindus have their grave faults, and also that both can be dignified and caring people. The reality of partition makes that realisation all the more wrenching, since there can never be real reconciliation across the India/Pakistan border. In that sense, it is similar to \"Mr & Mrs Iyer\".<br /><br />In the end, we were glad to have seen the film, even though the resolution was heartbreaking. If the UK and US could deal with their own histories of racism with this kind of frankness, they would certainly be better off.",
         "False"
        ],
        [
         "2",
         "negative",
         "Every once in a long while a movie will come along that will be so awful that I feel compelled to warn people. If I labor all my days and I can save but one soul from watching this movie, how great will be my joy.<br /><br />Where to begin my discussion of pain. For starters, there was a musical montage every five minutes. There was no character development. Every character was a stereotype. We had swearing guy, fat guy who eats donuts, goofy foreign guy, etc. The script felt as if it were being written as the movie was being shot. The production value was so incredibly low that it felt like I was watching a junior high video presentation. Have the directors, producers, etc. ever even seen a movie before? Halestorm is getting worse and worse with every new entry. The concept for this movie sounded so funny. How could you go wrong with Gary Coleman and a handful of somewhat legitimate actors. But trust me when I say this, things went wrong, VERY WRONG.",
         "False"
        ],
        [
         "3",
         "positive",
         "Name just says it all. I watched this movie with my dad when it came out and having served in Korea he had great admiration for the man. The disappointing thing about this film is that it only concentrate on a short period of the man's life - interestingly enough the man's entire life would have made such an epic bio-pic that it is staggering to imagine the cost for production.<br /><br />Some posters elude to the flawed characteristics about the man, which are cheap shots. The theme of the movie \"Duty, Honor, Country\" are not just mere words blathered from the lips of a high-brassed officer - it is the deep declaration of one man's total devotion to his country.<br /><br />Ironically Peck being the liberal that he was garnered a better understanding of the man. He does a great job showing the fearless general tempered with the humane side of the man.",
         "False"
        ],
        [
         "4",
         "negative",
         "This movie succeeds at being one of the most unique movies you've seen. However this comes from the fact that you can't make heads or tails of this mess. It almost seems as a series of challenges set up to determine whether or not you are willing to walk out of the movie and give up the money you just paid. If you don't want to feel slighted you'll sit through this horrible film and develop a real sense of pity for the actors involved, they've all seen better days, but then you realize they actually got paid quite a bit of money to do this and you'll lose pity for them just like you've already done for the film. I can't go on enough about this horrible movie, its almost something that Ed Wood would have made and in that case it surely would have been his masterpiece.<br /><br />To start you are forced to sit through an opening dialogue the likes of which you've never seen/heard, this thing has got to be five minutes long. On top of that it is narrated, as to suggest that you the viewer cannot read. Then we meet Mr. Slater and the barrage of terrible lines gets underway, it is as if he is operating solely to get lines on to the movie poster tag line. Soon we meet Stephen Dorff, who I typically enjoy) and he does his best not to drown in this but ultimately he does. Then comes the ultimate insult, Tara Reid playing an intelligent role, oh help us! Tara Reid is not a very talented actress and somehow she continually gets roles in movies, in my opinion though she should stick to movies of the American pie type. <br /><br />All in all you just may want to see this for yourself when it comes out on video, I know that I got a kick out of it, I mean lets all be honest here, sometimes its comforting to revel in the shortcomings of others.",
         "False"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.&lt;br /&gt;&lt;br /&gt;But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is som...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>Every once in a long while a movie will come along that will be so awful that I feel compelled to warn people. If I labor all my days and I can save but one soul from watching this movie, how great will be my joy.&lt;br /&gt;&lt;br /&gt;Where to begin my discussion of pain. For starters, there was a musical montage every five minutes. There was no character development. Every character was a stereotype. We had swearing guy, fat guy who eats donuts, goofy foreign guy, etc. The script felt as if it were being written as the movie was being shot. The production value was so incredibly low that it felt li...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Name just says it all. I watched this movie with my dad when it came out and having served in Korea he had great admiration for the man. The disappointing thing about this film is that it only concentrate on a short period of the man's life - interestingly enough the man's entire life would have made such an epic bio-pic that it is staggering to imagine the cost for production.&lt;br /&gt;&lt;br /&gt;Some posters elude to the flawed characteristics about the man, which are cheap shots. The theme of the movie \"Duty, Honor, Country\" are not just mere words blathered from the lips of a high-brassed offic...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>This movie succeeds at being one of the most unique movies you've seen. However this comes from the fact that you can't make heads or tails of this mess. It almost seems as a series of challenges set up to determine whether or not you are willing to walk out of the movie and give up the money you just paid. If you don't want to feel slighted you'll sit through this horrible film and develop a real sense of pity for the actors involved, they've all seen better days, but then you realize they actually got paid quite a bit of money to do this and you'll lose pity for them just like you've alr...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  \\\n",
       "0  negative   \n",
       "1  positive   \n",
       "2  negative   \n",
       "3  positive   \n",
       "4  negative   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0                                                                                                                                                                                                    Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!   \n",
       "1  This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.<br /><br />But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is som...   \n",
       "2  Every once in a long while a movie will come along that will be so awful that I feel compelled to warn people. If I labor all my days and I can save but one soul from watching this movie, how great will be my joy.<br /><br />Where to begin my discussion of pain. For starters, there was a musical montage every five minutes. There was no character development. Every character was a stereotype. We had swearing guy, fat guy who eats donuts, goofy foreign guy, etc. The script felt as if it were being written as the movie was being shot. The production value was so incredibly low that it felt li...   \n",
       "3  Name just says it all. I watched this movie with my dad when it came out and having served in Korea he had great admiration for the man. The disappointing thing about this film is that it only concentrate on a short period of the man's life - interestingly enough the man's entire life would have made such an epic bio-pic that it is staggering to imagine the cost for production.<br /><br />Some posters elude to the flawed characteristics about the man, which are cheap shots. The theme of the movie \"Duty, Honor, Country\" are not just mere words blathered from the lips of a high-brassed offic...   \n",
       "4  This movie succeeds at being one of the most unique movies you've seen. However this comes from the fact that you can't make heads or tails of this mess. It almost seems as a series of challenges set up to determine whether or not you are willing to walk out of the movie and give up the money you just paid. If you don't want to feel slighted you'll sit through this horrible film and develop a real sense of pity for the actors involved, they've all seen better days, but then you realize they actually got paid quite a bit of money to do this and you'll lose pity for them just like you've alr...   \n",
       "\n",
       "   is_valid  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'texts.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baa20063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.<br /><br />But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is some merit in this view, but it\\'s also true that no one forced Hindus and Muslims in the region to mistreat each other as they did around the time of partition. It seems more likely that the British simply saw the tensions between the religions and were clever enough to exploit them to their own ends.<br /><br />The result is that there is much cruelty and inhumanity in the situation and this is very unpleasant to remember and to see on the screen. But it is never painted as a black-and-white case. There is baseness and nobility on both sides, and also the hope for change in the younger generation.<br /><br />There is redemption of a sort, in the end, when Puro has to make a hard choice between a man who has ruined her life, but also truly loved her, and her family which has disowned her, then later come looking for her. But by that point, she has no option that is without great pain for her.<br /><br />This film carries the message that both Muslims and Hindus have their grave faults, and also that both can be dignified and caring people. The reality of partition makes that realisation all the more wrenching, since there can never be real reconciliation across the India/Pakistan border. In that sense, it is similar to \"Mr & Mrs Iyer\".<br /><br />In the end, we were glad to have seen the film, even though the resolution was heartbreaking. If the UK and US could deal with their own histories of racism with this kind of frankness, they would certainly be better off.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d467fb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `n_workers` has to be changed to 0 to avoid getting stuck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\data\\transforms.py:214: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  o = r[c] if isinstance(c, int) or not c in getattr(r, '_fields', []) else getattr(r, c)\n"
     ]
    }
   ],
   "source": [
    "from fastai.text import *\n",
    "# Tokenization และ Numericalization\n",
    "databunch_languagemodel = TextDataLoaders.from_csv(path=path, csv_fname='texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7baf995a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\data\\transforms.py:214: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  o = r[c] if isinstance(c, int) or not c in getattr(r, '_fields', []) else getattr(r, c)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos positive</td>\n",
       "      <td>Almost too well done... \"John Carpenter's Vampires\" was entertaining, a solid piece of popcorn-entertainment with a budget small enough not to be overrun by special effects. And obviously aiming on the \"From Dusk Till Dawn\"-audience. \"Vampires: Los Muertos\" tries the same starting with a rock-star Jon Bon Jovi playing one of the main characters, but does that almost too well...: I haven't seen Jon Bon Jovi in any other movie, so I am not able to compare his acting in \"Vampires: Los Muertos\" to his other roles, but I was really suprised of his good performance. After the movie started he convinced me not expecting him to grab any guitar and playing \"It' my life\" or something, but kill vampires, showing no mercy and doing a job which has to be done. This means a lot, because a part of the audience (also me) was probably thinking: \"...just because he's a rockstar...\". Of course Bon Jovi is not James Woods but to be honest: It could have been much worse, and in my opinion Bon Jovi did a very good performance. The vampiress played by Arly Jover is not the leather dressed killer-machine of a vampire-leader we met in Part 1 (or in similar way in \"Ghosts of Mars\"). Jover plays the vampire very seductive and very sexy, moving as lithe as a cat, attacking as fast as a snake and dressed in thin, light almost transparent very erotic cloth. And even the optical effects supporting her kind of movement are very well made. It really takes some beating. But the director is in some parts of the film only just avoiding turning the movie from an action-horrorfilm into a sensitive horrormovie like Murnau's \"Nosferatu\". You can almost see the director's temptation to create a movie with a VERY personal note and different to the original. This is the real strength of the movie and at the same time its weakest point: The audience celebrating the fun-bloodbath of the first movie is probably expecting a pure fun-bloodbath for the second time and might be a little disappointed. Make no mistake: \"Vampires:Los Muertos\" IS a fun-bloodbath but it's just not ALL THE TIME this kind of movie. Just think of the massacre in the bar compared to the scene in which the vampiress tries to seduce Zoey in the ruins: the bar-massacre is what you expect from american popcorn-entertainment, the seducing-Zoey-in-the-ruins-scene is ALMOST european-like cinema (the movie is eager to tell us more about the relationship between Zoey and the vampiress, but refuses answers at the same time. Because it would had slow down the action? Showed the audience a vampiress with a human past, a now suffering creature and not only a beast which is just slaughtering anybody). And that's the point to me which decides whether the movie is accepted by the audience of the original movie or not. And also: Is the \"From Dusk Till Dawn\"-audience really going to like this? I'm not sure about that. Nevertheless Tommy Lee Wallace did really a great job, \"Vampires:Los Muertos\" is surprisingly good. But I also think to direct a sequel of a popcorn movie Wallace is sometimes almost too creative, too expressive. Like he's keeping himself from developing his talent in order to satisfy the expectations of audience. In my opinion, Wallace' talent fills the movie with life and is maybe sometimes sucking it out at the same time. \"Vampires: Los Muertos\" is almost too well done. (I give it 7 of 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxbos negative</td>\n",
       "      <td>Although a film with Bruce Willis is always worth watching, you better skip this one. I watched this one on television, so I didn't have to plunk down cash for it. Lucky me.&lt;br /&gt;&lt;br /&gt;The plot develops slowly, very slowly. Although the first 30 minutes or so are quite believable, it gets more and more unbelievable towards the end. It is highly questionable, if a seasoned soldier like Lt. Waters would disobey direct orders. And even if he would, if the rest of his platoon would. They know he puts them in direct danger, and they know they will certainly die if they follow him, but what the heck, he is our Lt. so let's do what he says (despite the direct orders, remember).&lt;br /&gt;&lt;br /&gt;Still, there are some nice scenes in this movie. They somewhat save a village, where the total population is being massacred by the rebels. Well, they save a dozen villagers or so, the rest was already killed. The strange part of it, that they did take the trucks which the rebels left behind. They rather go on foot. Maybe because the roads are unsafe, but there was no explanation for it. Anyway. I think this was what earned the movie the one point I gave it.&lt;br /&gt;&lt;br /&gt;What made this movie an insult to the brain and hence completely unbelievable is that a group of 7 soldiers can kill of so many rebels without being hurt or killed themselves. Only near the end they loose a few comrades. And that is only because they have to fight of an army of nearly 500 or more. Can you believe that?&lt;br /&gt;&lt;br /&gt;They fight of an army of so many, kill hundreds of them, and only loose a few of themselves. And they have rounds and round of ammo. Never run out of it. Grenades and claymore mines, an M60 machine gun and even an RPG. Where do they get this stuff. Carrying it around or what? They even got a laptop which shows them the activity of enemy rebels. And this laptop has a battery which goes on for days. Really? Who think up this crap.&lt;br /&gt;&lt;br /&gt;I guess if you turn off your brain completely and accept that the rebels are a bunch of idiots, you give this movie a high rating. If not, skip this one. It saves you time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxbos positive</td>\n",
       "      <td>It's a very good movie, not only for the fans of Lady Death comics, but also for those who like animated movies/series of adventure and fantasy.&lt;br /&gt;&lt;br /&gt;The film is about a innocent girl who is about killed for something she hadn't done, but for be who she is daughter of the ruler of hell, Lucifer himself.&lt;br /&gt;&lt;br /&gt;Then she seeks revenge...and the rest you better see it from the movie.&lt;br /&gt;&lt;br /&gt;I liked the movie a lot, the characters are like the original comics, form Chaos. I never had the chance of read the the first parts of the story in comics, only the last ones, after the passages in the movie, so I cannot tell you if the events are exactly like the comics, but...one way or another it's the story of Lady Death!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "databunch_languagemodel.show_batch(max_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac47ba65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\data\\transforms.py:214: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  o = r[c] if isinstance(c, int) or not c in getattr(r, '_fields', []) else getattr(r, c)\n"
     ]
    }
   ],
   "source": [
    "x ,y = next(iter(databunch_languagemodel.train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d6bdde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "1",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "a6df6131-9f9d-40a4-a125-ee08717a3953",
       "rows": [
        [
         "0",
         "xxbos",
         "positive"
        ],
        [
         "1",
         "xxbos",
         "positive"
        ],
        [
         "2",
         "xxbos",
         "positive"
        ],
        [
         "3",
         "xxbos",
         "positive"
        ],
        [
         "4",
         "xxbos",
         "negative"
        ],
        [
         "5",
         "xxbos",
         "positive"
        ],
        [
         "6",
         "xxbos",
         "negative"
        ],
        [
         "7",
         "xxbos",
         "positive"
        ],
        [
         "8",
         "xxbos",
         "positive"
        ],
        [
         "9",
         "xxbos",
         "positive"
        ],
        [
         "10",
         "xxbos",
         "negative"
        ],
        [
         "11",
         "xxbos",
         "negative"
        ],
        [
         "12",
         "xxbos",
         "positive"
        ],
        [
         "13",
         "xxbos",
         "positive"
        ],
        [
         "14",
         "xxbos",
         "negative"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 15
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxbos</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxbos</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xxbos</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xxbos</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xxbos</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xxbos</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xxbos</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xxbos</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xxbos</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>xxbos</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>xxbos</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xxbos</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xxbos</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>xxbos</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1\n",
       "0   xxbos  positive\n",
       "1   xxbos  positive\n",
       "2   xxbos  positive\n",
       "3   xxbos  positive\n",
       "4   xxbos  negative\n",
       "5   xxbos  positive\n",
       "6   xxbos  negative\n",
       "7   xxbos  positive\n",
       "8   xxbos  positive\n",
       "9   xxbos  positive\n",
       "10  xxbos  negative\n",
       "11  xxbos  negative\n",
       "12  xxbos  positive\n",
       "13  xxbos  positive\n",
       "14  xxbos  negative"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = x[:15,:12].cpu()\n",
    "texts = pd.DataFrame([[databunch_languagemodel.vocab[0][int(i)] for i in l] for l in example])\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0ef7267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `n_workers` has to be changed to 0 to avoid getting stuck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.101054</td>\n",
       "      <td>4.029351</td>\n",
       "      <td>0.273581</td>\n",
       "      <td>56.224422</td>\n",
       "      <td>03:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.664382</td>\n",
       "      <td>3.974585</td>\n",
       "      <td>0.278463</td>\n",
       "      <td>53.228027</td>\n",
       "      <td>03:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.610569</td>\n",
       "      <td>3.982650</td>\n",
       "      <td>0.275504</td>\n",
       "      <td>53.659046</td>\n",
       "      <td>03:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.439035</td>\n",
       "      <td>4.013913</td>\n",
       "      <td>0.275728</td>\n",
       "      <td>55.363064</td>\n",
       "      <td>03:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.144295</td>\n",
       "      <td>4.093144</td>\n",
       "      <td>0.266109</td>\n",
       "      <td>59.928036</td>\n",
       "      <td>03:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.783416</td>\n",
       "      <td>4.239944</td>\n",
       "      <td>0.259020</td>\n",
       "      <td>69.403999</td>\n",
       "      <td>03:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.411587</td>\n",
       "      <td>4.394893</td>\n",
       "      <td>0.251767</td>\n",
       "      <td>81.035934</td>\n",
       "      <td>03:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.043587</td>\n",
       "      <td>4.570611</td>\n",
       "      <td>0.244384</td>\n",
       "      <td>96.603073</td>\n",
       "      <td>03:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.756358</td>\n",
       "      <td>4.678987</td>\n",
       "      <td>0.241206</td>\n",
       "      <td>107.660957</td>\n",
       "      <td>04:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.576973</td>\n",
       "      <td>4.758686</td>\n",
       "      <td>0.237117</td>\n",
       "      <td>116.592628</td>\n",
       "      <td>04:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.477384</td>\n",
       "      <td>4.779843</td>\n",
       "      <td>0.234990</td>\n",
       "      <td>119.085632</td>\n",
       "      <td>04:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "สร้าง language_model_learner ด้วย AWD-LSTM เป็นโมเดลแบบ RNN, LSTM ไว้เราจะอธิบายต่อไป\n",
    "\n",
    "AWD_LSTM เป็น Language Model ที่ได้ถูกเทรนมากับ Corpus ขนาดใหญ่ จากส่วนหนึ่งของ Wikipedia ชื่อ WikiText-103 มีขนาดใหญ่ถึง 103,227,021 Token และ 267,735 Vocab เรียบร้อยแล้ว\n",
    "\n",
    "กำหนดค่า drop_mult (Dropout) เรื่อง Regularization ไว้เราจะอธิบายต่อไป\n",
    "\"\"\"\n",
    "databunch_languagemodel = TextDataLoaders.from_csv(path, 'texts.csv', text_col='text', is_lm=True, valid_pct=0.1)\n",
    "learn = language_model_learner(databunch_languagemodel, AWD_LSTM, drop_mult=0.3, \n",
    "                               metrics=[accuracy, Perplexity()]).to_fp16()\n",
    "\n",
    "# เทรนรอบแรก (Freeze)\n",
    "learn.fit_one_cycle(1, 2e-2)\n",
    "\n",
    "# Save\n",
    "learn.save('1epoch')\n",
    "\n",
    "# เทรนต่อ (Unfreeze)\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(10, 2e-3)\n",
    "\n",
    "# Save Encoder (สำคัญ! เพื่อเอาไปใช้ต่อในขั้นตอน Classifier)\n",
    "learn.save_encoder('finetuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "773cbac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "f:\\Python_NLP\\learnning_nlp\\.venv\\Lib\\site-packages\\fastai\\callback\\fp16.py:47: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  self.autocast,self.learn.scaler,self.scales = autocast('cuda', dtype=dtype),GradScaler('cuda', **self.kwargs),L()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i liked this movie because the characters are well - developed and very developed . The characters are very developed and have a great deal of time . The friendship is such a bloom and i will never forget anyone when i watch\n",
      "i liked this movie because it 's like someone got a bunch of things to say about it , especially the idea that it is just not a type of movie like the John Lennon Story . Before you watch it\n"
     ]
    }
   ],
   "source": [
    "TEXT = \"I liked this movie because\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2\n",
    "\n",
    "preds = [learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)]\n",
    "print(\"\\n\".join(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0af0dde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learnning-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
