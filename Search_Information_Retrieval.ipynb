{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "723042f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "899132c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: '‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°'\n",
      "------------------------------\n",
      "‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö 1: Python ‡∏Ñ‡∏∑‡∏≠‡∏†‡∏≤‡∏©‡∏≤‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏¥‡∏¢‡∏°‡∏™‡∏π‡∏á\n",
      "‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö 2: ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° Python ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Data Science\n",
      "‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö 3: ‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏£‡πà‡∏≠‡∏¢ ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏¢‡πà‡∏≤‡∏ô‡∏™‡∏¢‡∏≤‡∏°\n",
      "\n",
      "\n",
      "üîé ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: '‡∏´‡∏∏‡πâ‡∏ô‡∏ï‡∏Å'\n",
      "------------------------------\n",
      "‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö 1: ‡∏ß‡∏¥‡∏ò‡∏µ‡∏î‡∏π‡∏Å‡∏£‡∏≤‡∏ü‡∏´‡∏∏‡πâ‡∏ô‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡πÉ‡∏´‡∏°‡πà\n",
      "‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö 2: ‡∏´‡∏∏‡πâ‡∏ô‡πÑ‡∏ó‡∏¢‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏õ‡∏¥‡∏î‡∏•‡∏ö 10 ‡∏à‡∏∏‡∏î ‡∏ô‡∏±‡∏Å‡∏•‡∏á‡∏ó‡∏∏‡∏ô‡∏Å‡∏±‡∏á‡∏ß‡∏•\n",
      "‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö 3: ‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏£‡πà‡∏≠‡∏¢ ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏¢‡πà‡∏≤‡∏ô‡∏™‡∏¢‡∏≤‡∏°\n",
      "\n",
      "\n",
      "üîé ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: '‡∏´‡∏≤‡∏Ç‡∏≠‡∏á‡∏Å‡∏¥‡∏ô'\n",
      "------------------------------\n",
      "‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö 1: Python ‡∏Ñ‡∏∑‡∏≠‡∏†‡∏≤‡∏©‡∏≤‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏¥‡∏¢‡∏°‡∏™‡∏π‡∏á\n",
      "‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö 2: ‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏£‡πà‡∏≠‡∏¢ ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏¢‡πà‡∏≤‡∏ô‡∏™‡∏¢‡∏≤‡∏°\n",
      "‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö 3: ‡∏´‡∏∏‡πâ‡∏ô‡πÑ‡∏ó‡∏¢‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏õ‡∏¥‡∏î‡∏•‡∏ö 10 ‡∏à‡∏∏‡∏î ‡∏ô‡∏±‡∏Å‡∏•‡∏á‡∏ó‡∏∏‡∏ô‡∏Å‡∏±‡∏á‡∏ß‡∏•\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "documents = [\n",
    "    \"‡∏ß‡∏¥‡∏ò‡∏µ‡∏î‡∏π‡∏Å‡∏£‡∏≤‡∏ü‡∏´‡∏∏‡πâ‡∏ô‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡πÉ‡∏´‡∏°‡πà\",          # Doc 0\n",
    "    \"‡πÅ‡∏°‡∏ß‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å ‡∏û‡∏±‡∏ô‡∏ò‡∏∏‡πå‡∏™‡∏Å‡πá‡∏≠‡∏ï‡∏ï‡∏¥‡∏ä‡πÇ‡∏ü‡∏•‡∏î‡πå ‡∏Å‡∏¥‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÄ‡∏°‡πá‡∏î\",    # Doc 1\n",
    "    \"‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° Python ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Data Science\", # Doc 2\n",
    "    \"‡∏´‡∏∏‡πâ‡∏ô‡πÑ‡∏ó‡∏¢‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏õ‡∏¥‡∏î‡∏•‡∏ö 10 ‡∏à‡∏∏‡∏î ‡∏ô‡∏±‡∏Å‡∏•‡∏á‡∏ó‡∏∏‡∏ô‡∏Å‡∏±‡∏á‡∏ß‡∏•\",      # Doc 3\n",
    "    \"‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏£‡πà‡∏≠‡∏¢ ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏¢‡πà‡∏≤‡∏ô‡∏™‡∏¢‡∏≤‡∏°\",               # Doc 4\n",
    "    \"Python ‡∏Ñ‡∏∑‡∏≠‡∏†‡∏≤‡∏©‡∏≤‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏¥‡∏¢‡∏°‡∏™‡∏π‡∏á\",    # Doc 5\n",
    "]\n",
    "\n",
    "tokenized_corpus = [word_tokenize(doc, engine=\"newmm\") for doc in documents]\n",
    "\n",
    "#  Indexing (BM25)\n",
    "# TF-IDF ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡πÉ‡∏ô Index\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "def search(query, n=3):\n",
    "    tokenized_query = word_tokenize(query, engine=\"newmm\")\n",
    "    \n",
    "    doc_scores = bm25.get_scores(tokenized_query)\n",
    "    \n",
    "    top_n = bm25.get_top_n(tokenized_query, documents, n=n)\n",
    "    \n",
    "    print(f\"üîé ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: '{query}'\")\n",
    "    print(\"-\" * 30)\n",
    "    for i, doc in enumerate(top_n):\n",
    "        print(f\"‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö {i+1}: {doc}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# --- ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ---\n",
    "search(\"‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°\") \n",
    "search(\"‡∏´‡∏∏‡πâ‡∏ô‡∏ï‡∏Å\")\n",
    "search(\"‡∏´‡∏≤‡∏Ç‡∏≠‡∏á‡∏Å‡∏¥‡∏ô\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e49507d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† AI ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: '‡∏™‡∏≠‡∏ô Coding ‡∏´‡∏ô‡πà‡∏≠‡∏¢'\n",
      "----------------------------------------\n",
      "Score: 0.4170 | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° Python ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Data Science\n",
      "Score: 0.3432 | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: Python ‡∏Ñ‡∏∑‡∏≠‡∏†‡∏≤‡∏©‡∏≤‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏¥‡∏¢‡∏°‡∏™‡∏π‡∏á\n",
      "Score: 0.1430 | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: ‡πÅ‡∏°‡∏ß‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å ‡∏û‡∏±‡∏ô‡∏ò‡∏∏‡πå‡∏™‡∏Å‡πá‡∏≠‡∏ï‡∏ï‡∏¥‡∏ä‡πÇ‡∏ü‡∏•‡∏î‡πå ‡∏Å‡∏¥‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÄ‡∏°‡πá‡∏î\n",
      "\n",
      "\n",
      "üß† AI ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: '‡∏ï‡∏•‡∏≤‡∏î‡∏ó‡∏∏‡∏ô‡∏ã‡∏ö‡πÄ‡∏ã‡∏≤'\n",
      "----------------------------------------\n",
      "Score: 0.5064 | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: ‡∏ß‡∏¥‡∏ò‡∏µ‡∏î‡∏π‡∏Å‡∏£‡∏≤‡∏ü‡∏´‡∏∏‡πâ‡∏ô‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡πÉ‡∏´‡∏°‡πà\n",
      "Score: 0.3766 | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: ‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏£‡πà‡∏≠‡∏¢ ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏¢‡πà‡∏≤‡∏ô‡∏™‡∏¢‡∏≤‡∏°\n",
      "Score: 0.3490 | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: ‡∏´‡∏∏‡πâ‡∏ô‡πÑ‡∏ó‡∏¢‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏õ‡∏¥‡∏î‡∏•‡∏ö 10 ‡∏à‡∏∏‡∏î ‡∏ô‡∏±‡∏Å‡∏•‡∏á‡∏ó‡∏∏‡∏ô‡∏Å‡∏±‡∏á‡∏ß‡∏•\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "\n",
    "print(\"‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•...\")\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "documents = [\n",
    "    \"‡∏ß‡∏¥‡∏ò‡∏µ‡∏î‡∏π‡∏Å‡∏£‡∏≤‡∏ü‡∏´‡∏∏‡πâ‡∏ô‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡πÉ‡∏´‡∏°‡πà\",\n",
    "    \"‡πÅ‡∏°‡∏ß‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å ‡∏û‡∏±‡∏ô‡∏ò‡∏∏‡πå‡∏™‡∏Å‡πá‡∏≠‡∏ï‡∏ï‡∏¥‡∏ä‡πÇ‡∏ü‡∏•‡∏î‡πå ‡∏Å‡∏¥‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÄ‡∏°‡πá‡∏î\",\n",
    "    \"‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏° Python ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Data Science\",\n",
    "    \"‡∏´‡∏∏‡πâ‡∏ô‡πÑ‡∏ó‡∏¢‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏õ‡∏¥‡∏î‡∏•‡∏ö 10 ‡∏à‡∏∏‡∏î ‡∏ô‡∏±‡∏Å‡∏•‡∏á‡∏ó‡∏∏‡∏ô‡∏Å‡∏±‡∏á‡∏ß‡∏•\",\n",
    "    \"‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏£‡πà‡∏≠‡∏¢ ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏¢‡πà‡∏≤‡∏ô‡∏™‡∏¢‡∏≤‡∏°\",\n",
    "    \"Python ‡∏Ñ‡∏∑‡∏≠‡∏†‡∏≤‡∏©‡∏≤‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏¥‡∏¢‡∏°‡∏™‡∏π‡∏á\",\n",
    "]\n",
    "\n",
    "corpus_embeddings = model.encode(documents, convert_to_tensor=True)\n",
    "\n",
    "def semantic_search(query, n=3):\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    \n",
    "    cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    \n",
    "    top_results = np.argsort(cos_scores.cpu().numpy())[-n:][::-1] # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏°‡∏≤‡∏Å‡πÑ‡∏õ‡∏ô‡πâ‡∏≠‡∏¢\n",
    "    \n",
    "    print(f\"üß† AI ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: '{query}'\")\n",
    "    print(\"-\" * 40)\n",
    "    for idx in top_results:\n",
    "        score = cos_scores[idx]\n",
    "        print(f\"Score: {score:.4f} | ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: {documents[idx]}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "semantic_search(\"‡∏™‡∏≠‡∏ô Coding ‡∏´‡∏ô‡πà‡∏≠‡∏¢\")  \n",
    "\n",
    "semantic_search(\"‡∏ï‡∏•‡∏≤‡∏î‡∏ó‡∏∏‡∏ô‡∏ã‡∏ö‡πÄ‡∏ã‡∏≤\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learnning-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
